{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BaselineCNN.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f43cdef138954e498518116c6b00a157":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9871a3ef6b5b40f4b5aeea6da2bcb0ca","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d83a3d4a49fd4aaaba6049b27ee26153","IPY_MODEL_cc92591cee1b44f6ac8d6b0ada8e0678"]}},"9871a3ef6b5b40f4b5aeea6da2bcb0ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d83a3d4a49fd4aaaba6049b27ee26153":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_33cf7c8e25f84e6dbb10a73745a74705","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4b34de1c174c47fba1c2fcc0c7c8684d"}},"cc92591cee1b44f6ac8d6b0ada8e0678":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fe79ad0ef3614c608f714a24d65e29d4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170500096/? [00:30&lt;00:00, 14706867.16it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e4994c8ace9462c9ed1a5fd2bda15b1"}},"33cf7c8e25f84e6dbb10a73745a74705":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4b34de1c174c47fba1c2fcc0c7c8684d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe79ad0ef3614c608f714a24d65e29d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2e4994c8ace9462c9ed1a5fd2bda15b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"JiKJqNTchIux","colab_type":"text"},"source":["# CIFAR-10 w/ default parameters\n","\n","Customization and further experiements will be presented in other notebooks. \n","\n","In this notebook, we follow this [tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) provided by PyTorch on the CIFAR-10 dataset as well other online tutorials to understand each individual component. \n","\n","---\n","\n","### Code\n","\n","\n","\n","- We start by importing the libraries we need to load the CIFAR-10 and build the model we are going to train."]},{"cell_type":"code","metadata":{"id":"R9siRDzi-tAI","colab_type":"code","colab":{}},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MVlpjiVh_sQP","colab_type":"text"},"source":["- In order to work with the images, we define a *transforms.Compose* that will be used to place them in a *Tensor* and then normalize each channel (RGB) such that values are in the [-1, 1] range instead of the [0, 1]"]},{"cell_type":"code","metadata":{"id":"w4lLQzXPIFRZ","colab_type":"code","colab":{}},"source":["transform = transforms.Compose([transforms.ToTensor(), \n","                                transforms.Normalize(mean=(0.5, 0.5, 0.5),\n","                                                     std=(0.5, 0.5, 0.5))])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iPWWbXxQIhzn","colab_type":"text"},"source":["- Now, we can load the CIFAR-10 data into train and test sets while transforming the images with the transformer defined above. We use the PyTorch Dataload to automatically split the two sets into smaller batches (iterating through them later will be faster). "]},{"cell_type":"code","metadata":{"id":"LAqZF9BOJUYv","colab_type":"code","outputId":"ff2807c3-0100-4794-db59-c37dc70e95fc","executionInfo":{"status":"ok","timestamp":1587048679608,"user_tz":240,"elapsed":17632,"user":{"displayName":"Mohamed Youssef Bouaouina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVaUN6hVH1ipE9ABdzBsOxRwUGSVjgJfQlR14c=s64","userId":"14898250469599041869"}},"colab":{"base_uri":"https://localhost:8080/","height":100,"referenced_widgets":["f43cdef138954e498518116c6b00a157","9871a3ef6b5b40f4b5aeea6da2bcb0ca","d83a3d4a49fd4aaaba6049b27ee26153","cc92591cee1b44f6ac8d6b0ada8e0678","33cf7c8e25f84e6dbb10a73745a74705","4b34de1c174c47fba1c2fcc0c7c8684d","fe79ad0ef3614c608f714a24d65e29d4","2e4994c8ace9462c9ed1a5fd2bda15b1"]}},"source":["trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n","                                          shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n","                                         shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', \n","           'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f43cdef138954e498518116c6b00a157","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VRFNU_QktadP","colab_type":"text"},"source":["- In order to improve speed of this task, training and testing will be done using the GPU provided by Colab instead of the default CPU."]},{"cell_type":"code","metadata":{"id":"3uuyx6k5uKUS","colab_type":"code","outputId":"e7b4d6ca-692c-4703-c993-8bf84ba209d2","executionInfo":{"status":"ok","timestamp":1587048683104,"user_tz":240,"elapsed":1535,"user":{"displayName":"Mohamed Youssef Bouaouina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVaUN6hVH1ipE9ABdzBsOxRwUGSVjgJfQlR14c=s64","userId":"14898250469599041869"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aAqCIF6PNLNm","colab_type":"text"},"source":["-  We are now ready to create our model for classifying the images. We construct the model by superposing successively the following hidden layers and using ReLU as the activation layer for every layer:\n","    1.   A convolutional layer with **3 input channels** (R, G, and B) and **6 output channels** using **5x5 filters/kernels** \n","    2.   A max pooling layer with a **stride of 2**\n","    3.   A convolutional layer with **6 input channels** and **16 output channels** using **5x5 filters** \n","    4.   A linear layer with **400 inputs** (16 channels of size 5x5) and **120 outputs**\n","    5.   A linear layer with **120 inputs** and **84 outputs**\n","    6.   A linear layer with **84 inputs** and **10 outputs** corresponding to the 10 classes we have in this classification task. "]},{"cell_type":"code","metadata":{"id":"sSRkvGEdNZ9v","colab_type":"code","outputId":"e77a4b5d-fcaf-41ac-cc49-bfe6189bed2c","executionInfo":{"status":"ok","timestamp":1587048698399,"user_tz":240,"elapsed":11392,"user":{"displayName":"Mohamed Youssef Bouaouina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVaUN6hVH1ipE9ABdzBsOxRwUGSVjgJfQlR14c=s64","userId":"14898250469599041869"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["import torch.nn as nn\n","import torch.nn.functional as func\n","\n","\n","class ConvNet(nn.Module):\n","    def __init__(self):\n","        super(ConvNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(400, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Defines a forward pass of the data through the model.\n","        Connects the different layers in the proper order. \n","        Uses ReLU as the activation function of the hidden units. \n","        \"\"\"\n","        x = self.pool(func.relu(self.conv1(x)))\n","        x = self.pool(func.relu(self.conv2(x)))\n","        # Reshape the tensor variable so it has 400 columns \n","        # Let PyTorch figure out how many rows are needed (-1)\n","        x = x.view(-1, 400)\n","        x = func.relu(self.fc1(x))\n","        x = func.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","# Instantiate our model to train it and evaluate it\n","net = ConvNet()\n","# Use the GPU for operations on the net\n","net.to(device)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConvNet(\n","  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","  (fc1): Linear(in_features=400, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=84, bias=True)\n","  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"QnlEbeKBmNF1","colab_type":"text"},"source":["- After defining our model, we choose the cross entropy loss as our loss function and use stochastic gradient descent with momentum to optimize our model."]},{"cell_type":"code","metadata":{"id":"ewRuzKczmX7I","colab_type":"code","colab":{}},"source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w6WJALhMm_ah","colab_type":"text"},"source":["- Now train the model"]},{"cell_type":"code","metadata":{"id":"xZ1WGrf-n2l4","colab_type":"code","outputId":"f5c9c242-e1ed-4fe0-b3d5-5642b4016a7c","executionInfo":{"status":"ok","timestamp":1587049215262,"user_tz":240,"elapsed":505883,"user":{"displayName":"Mohamed Youssef Bouaouina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVaUN6hVH1ipE9ABdzBsOxRwUGSVjgJfQlR14c=s64","userId":"14898250469599041869"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for epoch in range(11):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs and use them with the GPU\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","\n","        # clear the gradients computed in the previous pass\n","        optimizer.zero_grad()\n","\n","        # forward pass + compare to true labels\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backprop: calculate the gradient for every parameter x and add to x.grad\n","        loss.backward()\n","        \n","        # Subtract the gradient from current value\n","        # while taking into account momentum and learning rate\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 2000 == 1999:    # print every 2000 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","\n","print('Finished Training')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1,  2000] loss: 2.237\n","[1,  4000] loss: 1.894\n","[1,  6000] loss: 1.685\n","[1,  8000] loss: 1.586\n","[1, 10000] loss: 1.503\n","[1, 12000] loss: 1.459\n","[2,  2000] loss: 1.382\n","[2,  4000] loss: 1.355\n","[2,  6000] loss: 1.338\n","[2,  8000] loss: 1.360\n","[2, 10000] loss: 1.294\n","[2, 12000] loss: 1.276\n","[3,  2000] loss: 1.232\n","[3,  4000] loss: 1.206\n","[3,  6000] loss: 1.203\n","[3,  8000] loss: 1.187\n","[3, 10000] loss: 1.186\n","[3, 12000] loss: 1.162\n","[4,  2000] loss: 1.095\n","[4,  4000] loss: 1.112\n","[4,  6000] loss: 1.124\n","[4,  8000] loss: 1.112\n","[4, 10000] loss: 1.118\n","[4, 12000] loss: 1.085\n","[5,  2000] loss: 1.026\n","[5,  4000] loss: 1.034\n","[5,  6000] loss: 1.013\n","[5,  8000] loss: 1.051\n","[5, 10000] loss: 1.034\n","[5, 12000] loss: 1.044\n","[6,  2000] loss: 0.949\n","[6,  4000] loss: 0.964\n","[6,  6000] loss: 0.995\n","[6,  8000] loss: 0.979\n","[6, 10000] loss: 0.958\n","[6, 12000] loss: 1.006\n","[7,  2000] loss: 0.888\n","[7,  4000] loss: 0.921\n","[7,  6000] loss: 0.944\n","[7,  8000] loss: 0.921\n","[7, 10000] loss: 0.942\n","[7, 12000] loss: 0.951\n","[8,  2000] loss: 0.855\n","[8,  4000] loss: 0.850\n","[8,  6000] loss: 0.887\n","[8,  8000] loss: 0.907\n","[8, 10000] loss: 0.902\n","[8, 12000] loss: 0.913\n","[9,  2000] loss: 0.807\n","[9,  4000] loss: 0.824\n","[9,  6000] loss: 0.848\n","[9,  8000] loss: 0.871\n","[9, 10000] loss: 0.870\n","[9, 12000] loss: 0.886\n","[10,  2000] loss: 0.778\n","[10,  4000] loss: 0.809\n","[10,  6000] loss: 0.841\n","[10,  8000] loss: 0.826\n","[10, 10000] loss: 0.832\n","[10, 12000] loss: 0.852\n","[11,  2000] loss: 0.750\n","[11,  4000] loss: 0.775\n","[11,  6000] loss: 0.802\n","[11,  8000] loss: 0.801\n","[11, 10000] loss: 0.814\n","[11, 12000] loss: 0.828\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wOv7w2BIoHm0","colab_type":"text"},"source":["- We evaluate the model on the test set"]},{"cell_type":"code","metadata":{"id":"GY5fFuFLqH54","colab_type":"code","outputId":"c7510197-90a2-4e66-d14d-5978835cee78","executionInfo":{"status":"ok","timestamp":1587049256907,"user_tz":240,"elapsed":7483,"user":{"displayName":"Mohamed Youssef Bouaouina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVaUN6hVH1ipE9ABdzBsOxRwUGSVjgJfQlR14c=s64","userId":"14898250469599041869"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["correct = 0\n","total = 0\n","with torch.no_grad(): # do not change the gradients of the variables\n","    for data in testloader:\n","        images, labels = data[0].to(device), data[1].to(device)\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (\n","    100 * correct / total))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 10000 test images: 62 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qreQ1WYurHVH","colab_type":"text"},"source":["- Accuracy on each class"]},{"cell_type":"code","metadata":{"id":"VeRw51EkrLtA","colab_type":"code","outputId":"2a78cbd0-a170-4215-edb8-2f478d08c22b","executionInfo":{"status":"ok","timestamp":1587049269985,"user_tz":240,"elapsed":7390,"user":{"displayName":"Mohamed Youssef Bouaouina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVaUN6hVH1ipE9ABdzBsOxRwUGSVjgJfQlR14c=s64","userId":"14898250469599041869"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["class_correct = list(0. for i in range(10))\n","class_total = list(0. for i in range(10))\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data[0].to(device), data[1].to(device)\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs, 1)\n","        c = (predicted == labels).squeeze()\n","        for i in range(4):\n","            label = labels[i]\n","            class_correct[label] += c[i].item()\n","            class_total[label] += 1\n","\n","\n","for i in range(10):\n","    print('Accuracy of %5s : %2d %%' % (\n","        classes[i], 100 * class_correct[i] / class_total[i]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy of plane : 64 %\n","Accuracy of   car : 71 %\n","Accuracy of  bird : 47 %\n","Accuracy of   cat : 37 %\n","Accuracy of  deer : 63 %\n","Accuracy of   dog : 58 %\n","Accuracy of  frog : 64 %\n","Accuracy of horse : 61 %\n","Accuracy of  ship : 81 %\n","Accuracy of truck : 75 %\n"],"name":"stdout"}]}]}